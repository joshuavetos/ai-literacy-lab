version: '3.9'

services:
  llm_server:
    build: .
    container_name: ai_literacy_lab_llm
    ports:
      - "8080:8080"
    networks:
      - ai_lab_net
  verifier:
    build:
      context: .
      dockerfile: verifier.Dockerfile
    working_dir: /app/sandbox
    volumes:
      - ../sandbox:/app/sandbox
    depends_on:
      - llm_server
    command: ["pytest", "-q"]
    networks:
      - ai_lab_net

networks:
  ai_lab_net:
    driver: bridge
