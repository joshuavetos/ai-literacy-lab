# Module 07 â€” Case Studies: When Fluency Failed Publicly

### 1. Objective
Connect abstract epistemic failures to real-world consequences.

### 2. The Illusion (Why)
The 2023 Avianca court filing cited fabricated cases produced by ChatGPT.

### 3. Mechanism (How)
Lawyers accepted fluent text as verified precedent; absent verification chain.  

### 4. Verification Method (Action)
1. Read each provided static HTML case file.  
2. Identify the unsupported citation.  
3. Map failure to prior module concept (e.g., Module 04: Cross-Validation).  

### 5. Verification Check
1. Which epistemic failure occurred?  
2. What procedural safeguard would have prevented it?  
3. How does this case justify reproducible AI audits?
